{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 20.0,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04,
      "learning_rate": 0.002994,
      "loss": 5.7852,
      "step": 1
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.002988,
      "loss": 7.228,
      "step": 2
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.002982,
      "loss": 5.527,
      "step": 3
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.002976,
      "loss": 5.1111,
      "step": 4
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00297,
      "loss": 7.1794,
      "step": 5
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.002964,
      "loss": 4.0156,
      "step": 6
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.002958,
      "loss": 9.5062,
      "step": 7
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.002952,
      "loss": 8.7299,
      "step": 8
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.002946,
      "loss": 8.9681,
      "step": 9
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00294,
      "loss": 4.8395,
      "step": 10
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.002934,
      "loss": 8.865,
      "step": 11
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.002928,
      "loss": 6.0218,
      "step": 12
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.002922,
      "loss": 5.4549,
      "step": 13
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.002916,
      "loss": 2.2286,
      "step": 14
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00291,
      "loss": 6.9937,
      "step": 15
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.002904,
      "loss": 7.9082,
      "step": 16
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.002898,
      "loss": 4.3671,
      "step": 17
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.002892,
      "loss": 5.6797,
      "step": 18
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.002886,
      "loss": 5.2616,
      "step": 19
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0028799999999999997,
      "loss": 3.456,
      "step": 20
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.002874,
      "loss": 5.6889,
      "step": 21
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.002868,
      "loss": 5.7684,
      "step": 22
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.002862,
      "loss": 4.0591,
      "step": 23
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.002856,
      "loss": 5.4968,
      "step": 24
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00285,
      "loss": 7.0028,
      "step": 25
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0028439999999999997,
      "loss": 4.0163,
      "step": 26
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.002838,
      "loss": 7.5066,
      "step": 27
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.002832,
      "loss": 6.89,
      "step": 28
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.002826,
      "loss": 5.7543,
      "step": 29
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.00282,
      "loss": 8.0803,
      "step": 30
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.002814,
      "loss": 5.5315,
      "step": 31
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.002808,
      "loss": 4.3017,
      "step": 32
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0028020000000000002,
      "loss": 6.604,
      "step": 33
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0027960000000000003,
      "loss": 4.8001,
      "step": 34
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0027900000000000004,
      "loss": 3.7615,
      "step": 35
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.002784,
      "loss": 3.2715,
      "step": 36
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.002778,
      "loss": 2.1809,
      "step": 37
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.002772,
      "loss": 5.3529,
      "step": 38
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0027660000000000002,
      "loss": 8.4251,
      "step": 39
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0027600000000000003,
      "loss": 5.4182,
      "step": 40
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0027540000000000004,
      "loss": 5.4525,
      "step": 41
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.002748,
      "loss": 7.6573,
      "step": 42
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.002742,
      "loss": 5.491,
      "step": 43
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.002736,
      "loss": 4.6164,
      "step": 44
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0027300000000000002,
      "loss": 6.5574,
      "step": 45
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0027240000000000003,
      "loss": 5.0739,
      "step": 46
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.002718,
      "loss": 5.1151,
      "step": 47
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.002712,
      "loss": 7.4746,
      "step": 48
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.002706,
      "loss": 5.2439,
      "step": 49
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0027,
      "loss": 4.4506,
      "step": 50
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.002694,
      "loss": 5.2054,
      "step": 51
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0026880000000000003,
      "loss": 5.2823,
      "step": 52
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.002682,
      "loss": 4.5749,
      "step": 53
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.002676,
      "loss": 2.1494,
      "step": 54
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.00267,
      "loss": 3.8059,
      "step": 55
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.002664,
      "loss": 5.4775,
      "step": 56
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.002658,
      "loss": 5.0651,
      "step": 57
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.0026520000000000003,
      "loss": 5.2524,
      "step": 58
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.002646,
      "loss": 6.175,
      "step": 59
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.00264,
      "loss": 7.3786,
      "step": 60
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.002634,
      "loss": 6.3542,
      "step": 61
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.002628,
      "loss": 4.2127,
      "step": 62
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.002622,
      "loss": 4.4701,
      "step": 63
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.002616,
      "loss": 4.4188,
      "step": 64
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.00261,
      "loss": 8.2622,
      "step": 65
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.002604,
      "loss": 3.1431,
      "step": 66
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.002598,
      "loss": 3.6292,
      "step": 67
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.002592,
      "loss": 4.9865,
      "step": 68
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.002586,
      "loss": 6.6976,
      "step": 69
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.00258,
      "loss": 6.0637,
      "step": 70
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.002574,
      "loss": 5.2284,
      "step": 71
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.002568,
      "loss": 6.5218,
      "step": 72
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.002562,
      "loss": 5.3486,
      "step": 73
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.002556,
      "loss": 7.125,
      "step": 74
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.00255,
      "loss": 4.9102,
      "step": 75
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.002544,
      "loss": 4.9869,
      "step": 76
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.002538,
      "loss": 6.0724,
      "step": 77
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.002532,
      "loss": 6.9895,
      "step": 78
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.002526,
      "loss": 6.2655,
      "step": 79
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.00252,
      "loss": 3.5839,
      "step": 80
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.0025139999999999997,
      "loss": 4.2024,
      "step": 81
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.002508,
      "loss": 4.9395,
      "step": 82
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.002502,
      "loss": 4.9905,
      "step": 83
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.002496,
      "loss": 3.7441,
      "step": 84
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.00249,
      "loss": 3.0778,
      "step": 85
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.002484,
      "loss": 4.8515,
      "step": 86
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.0024779999999999997,
      "loss": 2.1124,
      "step": 87
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.002472,
      "loss": 5.4176,
      "step": 88
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.002466,
      "loss": 5.0869,
      "step": 89
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.00246,
      "loss": 5.2899,
      "step": 90
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.002454,
      "loss": 6.8256,
      "step": 91
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.002448,
      "loss": 4.592,
      "step": 92
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.0024419999999999997,
      "loss": 8.1041,
      "step": 93
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.0024360000000000002,
      "loss": 4.9907,
      "step": 94
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.0024300000000000003,
      "loss": 6.3717,
      "step": 95
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.0024240000000000004,
      "loss": 4.5242,
      "step": 96
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.002418,
      "loss": 5.9326,
      "step": 97
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.002412,
      "loss": 4.2852,
      "step": 98
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.002406,
      "loss": 4.3205,
      "step": 99
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.0024000000000000002,
      "loss": 6.2042,
      "step": 100
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.0023940000000000003,
      "loss": 5.0236,
      "step": 101
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.0023880000000000004,
      "loss": 3.7048,
      "step": 102
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.002382,
      "loss": 4.2092,
      "step": 103
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.002376,
      "loss": 5.9181,
      "step": 104
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.00237,
      "loss": 6.2726,
      "step": 105
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.002364,
      "loss": 8.0151,
      "step": 106
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.0023580000000000003,
      "loss": 6.6176,
      "step": 107
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.002352,
      "loss": 4.4971,
      "step": 108
    },
    {
      "epoch": 4.36,
      "learning_rate": 0.002346,
      "loss": 6.1688,
      "step": 109
    },
    {
      "epoch": 4.4,
      "learning_rate": 0.00234,
      "loss": 4.7279,
      "step": 110
    },
    {
      "epoch": 4.44,
      "learning_rate": 0.002334,
      "loss": 3.4972,
      "step": 111
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.002328,
      "loss": 4.3339,
      "step": 112
    },
    {
      "epoch": 4.52,
      "learning_rate": 0.0023220000000000003,
      "loss": 5.3512,
      "step": 113
    },
    {
      "epoch": 4.56,
      "learning_rate": 0.002316,
      "loss": 2.0969,
      "step": 114
    },
    {
      "epoch": 4.6,
      "learning_rate": 0.00231,
      "loss": 4.8269,
      "step": 115
    },
    {
      "epoch": 4.64,
      "learning_rate": 0.002304,
      "loss": 4.2818,
      "step": 116
    },
    {
      "epoch": 4.68,
      "learning_rate": 0.002298,
      "loss": 2.968,
      "step": 117
    },
    {
      "epoch": 4.72,
      "learning_rate": 0.002292,
      "loss": 4.857,
      "step": 118
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.0022860000000000003,
      "loss": 5.2049,
      "step": 119
    },
    {
      "epoch": 4.8,
      "learning_rate": 0.00228,
      "loss": 4.8185,
      "step": 120
    },
    {
      "epoch": 4.84,
      "learning_rate": 0.002274,
      "loss": 4.2064,
      "step": 121
    },
    {
      "epoch": 4.88,
      "learning_rate": 0.002268,
      "loss": 5.4321,
      "step": 122
    },
    {
      "epoch": 4.92,
      "learning_rate": 0.002262,
      "loss": 6.5635,
      "step": 123
    },
    {
      "epoch": 4.96,
      "learning_rate": 0.002256,
      "loss": 5.8332,
      "step": 124
    },
    {
      "epoch": 5.0,
      "learning_rate": 0.0022500000000000003,
      "loss": 4.8463,
      "step": 125
    },
    {
      "epoch": 5.04,
      "learning_rate": 0.002244,
      "loss": 4.1877,
      "step": 126
    },
    {
      "epoch": 5.08,
      "learning_rate": 0.002238,
      "loss": 4.783,
      "step": 127
    },
    {
      "epoch": 5.12,
      "learning_rate": 0.002232,
      "loss": 2.0886,
      "step": 128
    },
    {
      "epoch": 5.16,
      "learning_rate": 0.002226,
      "loss": 4.4661,
      "step": 129
    },
    {
      "epoch": 5.2,
      "learning_rate": 0.00222,
      "loss": 6.5021,
      "step": 130
    },
    {
      "epoch": 5.24,
      "learning_rate": 0.002214,
      "loss": 4.8309,
      "step": 131
    },
    {
      "epoch": 5.28,
      "learning_rate": 0.002208,
      "loss": 6.0768,
      "step": 132
    },
    {
      "epoch": 5.32,
      "learning_rate": 0.002202,
      "loss": 2.9431,
      "step": 133
    },
    {
      "epoch": 5.36,
      "learning_rate": 0.002196,
      "loss": 5.9967,
      "step": 134
    },
    {
      "epoch": 5.4,
      "learning_rate": 0.00219,
      "loss": 4.639,
      "step": 135
    },
    {
      "epoch": 5.44,
      "learning_rate": 0.002184,
      "loss": 5.7452,
      "step": 136
    },
    {
      "epoch": 5.48,
      "learning_rate": 0.002178,
      "loss": 4.2473,
      "step": 137
    },
    {
      "epoch": 5.52,
      "learning_rate": 0.002172,
      "loss": 6.4159,
      "step": 138
    },
    {
      "epoch": 5.56,
      "learning_rate": 0.002166,
      "loss": 5.1534,
      "step": 139
    },
    {
      "epoch": 5.6,
      "learning_rate": 0.00216,
      "loss": 4.8809,
      "step": 140
    },
    {
      "epoch": 5.64,
      "learning_rate": 0.002154,
      "loss": 3.6185,
      "step": 141
    },
    {
      "epoch": 5.68,
      "learning_rate": 0.002148,
      "loss": 3.9648,
      "step": 142
    },
    {
      "epoch": 5.72,
      "learning_rate": 0.002142,
      "loss": 4.8083,
      "step": 143
    },
    {
      "epoch": 5.76,
      "learning_rate": 0.002136,
      "loss": 4.1799,
      "step": 144
    },
    {
      "epoch": 5.8,
      "learning_rate": 0.00213,
      "loss": 5.8453,
      "step": 145
    },
    {
      "epoch": 5.84,
      "learning_rate": 0.002124,
      "loss": 7.8884,
      "step": 146
    },
    {
      "epoch": 5.88,
      "learning_rate": 0.002118,
      "loss": 4.9166,
      "step": 147
    },
    {
      "epoch": 5.92,
      "learning_rate": 0.0021119999999999997,
      "loss": 3.4247,
      "step": 148
    },
    {
      "epoch": 5.96,
      "learning_rate": 0.002106,
      "loss": 4.6274,
      "step": 149
    },
    {
      "epoch": 6.0,
      "learning_rate": 0.0021,
      "loss": 5.2501,
      "step": 150
    },
    {
      "epoch": 6.04,
      "learning_rate": 0.002094,
      "loss": 5.9987,
      "step": 151
    },
    {
      "epoch": 6.08,
      "learning_rate": 0.002088,
      "loss": 4.794,
      "step": 152
    },
    {
      "epoch": 6.12,
      "learning_rate": 0.002082,
      "loss": 4.0936,
      "step": 153
    },
    {
      "epoch": 6.16,
      "learning_rate": 0.0020759999999999997,
      "loss": 4.2055,
      "step": 154
    },
    {
      "epoch": 6.2,
      "learning_rate": 0.00207,
      "loss": 4.7843,
      "step": 155
    },
    {
      "epoch": 6.24,
      "learning_rate": 0.002064,
      "loss": 4.7668,
      "step": 156
    },
    {
      "epoch": 6.28,
      "learning_rate": 0.0020580000000000004,
      "loss": 4.6627,
      "step": 157
    },
    {
      "epoch": 6.32,
      "learning_rate": 0.002052,
      "loss": 5.1063,
      "step": 158
    },
    {
      "epoch": 6.36,
      "learning_rate": 0.002046,
      "loss": 5.5366,
      "step": 159
    },
    {
      "epoch": 6.4,
      "learning_rate": 0.00204,
      "loss": 3.4042,
      "step": 160
    },
    {
      "epoch": 6.44,
      "learning_rate": 0.0020340000000000002,
      "loss": 4.6067,
      "step": 161
    },
    {
      "epoch": 6.48,
      "learning_rate": 0.0020280000000000003,
      "loss": 3.6084,
      "step": 162
    },
    {
      "epoch": 6.52,
      "learning_rate": 0.0020220000000000004,
      "loss": 4.4464,
      "step": 163
    },
    {
      "epoch": 6.56,
      "learning_rate": 0.002016,
      "loss": 2.8811,
      "step": 164
    },
    {
      "epoch": 6.6,
      "learning_rate": 0.00201,
      "loss": 6.3054,
      "step": 165
    },
    {
      "epoch": 6.64,
      "learning_rate": 0.002004,
      "loss": 4.4338,
      "step": 166
    },
    {
      "epoch": 6.68,
      "learning_rate": 0.001998,
      "loss": 5.7319,
      "step": 167
    },
    {
      "epoch": 6.72,
      "learning_rate": 0.0019920000000000003,
      "loss": 6.0832,
      "step": 168
    },
    {
      "epoch": 6.76,
      "learning_rate": 0.0019860000000000004,
      "loss": 7.7422,
      "step": 169
    },
    {
      "epoch": 6.8,
      "learning_rate": 0.00198,
      "loss": 5.6116,
      "step": 170
    },
    {
      "epoch": 6.84,
      "learning_rate": 0.001974,
      "loss": 4.143,
      "step": 171
    },
    {
      "epoch": 6.88,
      "learning_rate": 0.001968,
      "loss": 2.0743,
      "step": 172
    },
    {
      "epoch": 6.92,
      "learning_rate": 0.001962,
      "loss": 4.7717,
      "step": 173
    },
    {
      "epoch": 6.96,
      "learning_rate": 0.0019560000000000003,
      "loss": 3.5301,
      "step": 174
    },
    {
      "epoch": 7.0,
      "learning_rate": 0.0019500000000000001,
      "loss": 5.1805,
      "step": 175
    },
    {
      "epoch": 7.04,
      "learning_rate": 0.0019440000000000002,
      "loss": 5.1767,
      "step": 176
    },
    {
      "epoch": 7.08,
      "learning_rate": 0.001938,
      "loss": 4.6079,
      "step": 177
    },
    {
      "epoch": 7.12,
      "learning_rate": 0.0019320000000000001,
      "loss": 2.0719,
      "step": 178
    },
    {
      "epoch": 7.16,
      "learning_rate": 0.001926,
      "loss": 5.0582,
      "step": 179
    },
    {
      "epoch": 7.2,
      "learning_rate": 0.00192,
      "loss": 4.7092,
      "step": 180
    },
    {
      "epoch": 7.24,
      "learning_rate": 0.0019140000000000001,
      "loss": 4.4156,
      "step": 181
    },
    {
      "epoch": 7.28,
      "learning_rate": 0.001908,
      "loss": 5.4517,
      "step": 182
    },
    {
      "epoch": 7.32,
      "learning_rate": 0.001902,
      "loss": 3.5908,
      "step": 183
    },
    {
      "epoch": 7.36,
      "learning_rate": 0.0018960000000000001,
      "loss": 4.7472,
      "step": 184
    },
    {
      "epoch": 7.4,
      "learning_rate": 0.00189,
      "loss": 6.1416,
      "step": 185
    },
    {
      "epoch": 7.44,
      "learning_rate": 0.001884,
      "loss": 2.8357,
      "step": 186
    },
    {
      "epoch": 7.48,
      "learning_rate": 0.0018780000000000001,
      "loss": 3.3584,
      "step": 187
    },
    {
      "epoch": 7.52,
      "learning_rate": 0.001872,
      "loss": 4.1035,
      "step": 188
    },
    {
      "epoch": 7.56,
      "learning_rate": 0.001866,
      "loss": 4.2738,
      "step": 189
    },
    {
      "epoch": 7.6,
      "learning_rate": 0.00186,
      "loss": 3.36,
      "step": 190
    },
    {
      "epoch": 7.64,
      "learning_rate": 0.001854,
      "loss": 5.7487,
      "step": 191
    },
    {
      "epoch": 7.68,
      "learning_rate": 0.001848,
      "loss": 5.2861,
      "step": 192
    },
    {
      "epoch": 7.72,
      "learning_rate": 0.001842,
      "loss": 4.3422,
      "step": 193
    },
    {
      "epoch": 7.76,
      "learning_rate": 0.001836,
      "loss": 4.1198,
      "step": 194
    },
    {
      "epoch": 7.8,
      "learning_rate": 0.00183,
      "loss": 4.7066,
      "step": 195
    },
    {
      "epoch": 7.84,
      "learning_rate": 0.001824,
      "loss": 7.6121,
      "step": 196
    },
    {
      "epoch": 7.88,
      "learning_rate": 0.001818,
      "loss": 4.5017,
      "step": 197
    },
    {
      "epoch": 7.92,
      "learning_rate": 0.001812,
      "loss": 5.8755,
      "step": 198
    },
    {
      "epoch": 7.96,
      "learning_rate": 0.0018059999999999999,
      "loss": 5.5578,
      "step": 199
    },
    {
      "epoch": 8.0,
      "learning_rate": 0.0018,
      "loss": 3.9216,
      "step": 200
    },
    {
      "epoch": 8.04,
      "learning_rate": 0.001794,
      "loss": 7.5632,
      "step": 201
    },
    {
      "epoch": 8.08,
      "learning_rate": 0.0017879999999999999,
      "loss": 4.4841,
      "step": 202
    },
    {
      "epoch": 8.12,
      "learning_rate": 0.001782,
      "loss": 4.6633,
      "step": 203
    },
    {
      "epoch": 8.16,
      "learning_rate": 0.001776,
      "loss": 4.5668,
      "step": 204
    },
    {
      "epoch": 8.2,
      "learning_rate": 0.0017699999999999999,
      "loss": 5.1439,
      "step": 205
    },
    {
      "epoch": 8.24,
      "learning_rate": 0.001764,
      "loss": 2.0608,
      "step": 206
    },
    {
      "epoch": 8.28,
      "learning_rate": 0.001758,
      "loss": 4.1701,
      "step": 207
    },
    {
      "epoch": 8.32,
      "learning_rate": 0.0017519999999999999,
      "loss": 5.4956,
      "step": 208
    },
    {
      "epoch": 8.36,
      "learning_rate": 0.001746,
      "loss": 4.3658,
      "step": 209
    },
    {
      "epoch": 8.4,
      "learning_rate": 0.00174,
      "loss": 3.5415,
      "step": 210
    },
    {
      "epoch": 8.44,
      "learning_rate": 0.0017339999999999999,
      "loss": 5.4944,
      "step": 211
    },
    {
      "epoch": 8.48,
      "learning_rate": 0.001728,
      "loss": 4.9893,
      "step": 212
    },
    {
      "epoch": 8.52,
      "learning_rate": 0.001722,
      "loss": 4.2229,
      "step": 213
    },
    {
      "epoch": 8.56,
      "learning_rate": 0.0017159999999999999,
      "loss": 3.1922,
      "step": 214
    },
    {
      "epoch": 8.6,
      "learning_rate": 0.00171,
      "loss": 5.83,
      "step": 215
    },
    {
      "epoch": 8.64,
      "learning_rate": 0.0017039999999999998,
      "loss": 5.0575,
      "step": 216
    },
    {
      "epoch": 8.68,
      "learning_rate": 0.0016979999999999999,
      "loss": 3.3257,
      "step": 217
    },
    {
      "epoch": 8.72,
      "learning_rate": 0.001692,
      "loss": 4.0401,
      "step": 218
    },
    {
      "epoch": 8.76,
      "learning_rate": 0.0016860000000000002,
      "loss": 3.8601,
      "step": 219
    },
    {
      "epoch": 8.8,
      "learning_rate": 0.0016800000000000003,
      "loss": 5.8961,
      "step": 220
    },
    {
      "epoch": 8.84,
      "learning_rate": 0.0016740000000000001,
      "loss": 2.7613,
      "step": 221
    },
    {
      "epoch": 8.88,
      "learning_rate": 0.0016680000000000002,
      "loss": 5.0452,
      "step": 222
    },
    {
      "epoch": 8.92,
      "learning_rate": 0.0016620000000000003,
      "loss": 4.6461,
      "step": 223
    },
    {
      "epoch": 8.96,
      "learning_rate": 0.0016560000000000001,
      "loss": 4.0626,
      "step": 224
    },
    {
      "epoch": 9.0,
      "learning_rate": 0.0016500000000000002,
      "loss": 4.6955,
      "step": 225
    },
    {
      "epoch": 9.04,
      "learning_rate": 0.001644,
      "loss": 4.5243,
      "step": 226
    },
    {
      "epoch": 9.08,
      "learning_rate": 0.0016380000000000001,
      "loss": 5.231,
      "step": 227
    },
    {
      "epoch": 9.12,
      "learning_rate": 0.0016320000000000002,
      "loss": 3.3145,
      "step": 228
    },
    {
      "epoch": 9.16,
      "learning_rate": 0.001626,
      "loss": 5.4115,
      "step": 229
    },
    {
      "epoch": 9.2,
      "learning_rate": 0.0016200000000000001,
      "loss": 4.0493,
      "step": 230
    },
    {
      "epoch": 9.24,
      "learning_rate": 0.0016140000000000002,
      "loss": 2.048,
      "step": 231
    },
    {
      "epoch": 9.28,
      "learning_rate": 0.001608,
      "loss": 5.8008,
      "step": 232
    },
    {
      "epoch": 9.32,
      "learning_rate": 0.0016020000000000001,
      "loss": 4.6237,
      "step": 233
    },
    {
      "epoch": 9.36,
      "learning_rate": 0.0015960000000000002,
      "loss": 4.9239,
      "step": 234
    },
    {
      "epoch": 9.4,
      "learning_rate": 0.00159,
      "loss": 4.7994,
      "step": 235
    },
    {
      "epoch": 9.44,
      "learning_rate": 0.0015840000000000001,
      "loss": 3.8223,
      "step": 236
    },
    {
      "epoch": 9.48,
      "learning_rate": 0.0015780000000000002,
      "loss": 7.3661,
      "step": 237
    },
    {
      "epoch": 9.52,
      "learning_rate": 0.001572,
      "loss": 3.5075,
      "step": 238
    },
    {
      "epoch": 9.56,
      "learning_rate": 0.0015660000000000001,
      "loss": 2.732,
      "step": 239
    },
    {
      "epoch": 9.6,
      "learning_rate": 0.0015600000000000002,
      "loss": 5.7501,
      "step": 240
    },
    {
      "epoch": 9.64,
      "learning_rate": 0.001554,
      "loss": 4.9538,
      "step": 241
    },
    {
      "epoch": 9.68,
      "learning_rate": 0.0015480000000000001,
      "loss": 5.0107,
      "step": 242
    },
    {
      "epoch": 9.72,
      "learning_rate": 0.001542,
      "loss": 4.6094,
      "step": 243
    },
    {
      "epoch": 9.76,
      "learning_rate": 0.001536,
      "loss": 4.3832,
      "step": 244
    },
    {
      "epoch": 9.8,
      "learning_rate": 0.0015300000000000001,
      "loss": 4.3135,
      "step": 245
    },
    {
      "epoch": 9.84,
      "learning_rate": 0.001524,
      "loss": 4.6778,
      "step": 246
    },
    {
      "epoch": 9.88,
      "learning_rate": 0.001518,
      "loss": 3.9943,
      "step": 247
    },
    {
      "epoch": 9.92,
      "learning_rate": 0.001512,
      "loss": 4.1008,
      "step": 248
    },
    {
      "epoch": 9.96,
      "learning_rate": 0.001506,
      "loss": 3.0582,
      "step": 249
    },
    {
      "epoch": 10.0,
      "learning_rate": 0.0015,
      "loss": 4.062,
      "step": 250
    },
    {
      "epoch": 10.04,
      "learning_rate": 0.001494,
      "loss": 4.9412,
      "step": 251
    },
    {
      "epoch": 10.08,
      "learning_rate": 0.001488,
      "loss": 4.7899,
      "step": 252
    },
    {
      "epoch": 10.12,
      "learning_rate": 0.001482,
      "loss": 4.9672,
      "step": 253
    },
    {
      "epoch": 10.16,
      "learning_rate": 0.001476,
      "loss": 5.7161,
      "step": 254
    },
    {
      "epoch": 10.2,
      "learning_rate": 0.00147,
      "loss": 3.7973,
      "step": 255
    },
    {
      "epoch": 10.24,
      "learning_rate": 0.001464,
      "loss": 5.6775,
      "step": 256
    },
    {
      "epoch": 10.28,
      "learning_rate": 0.001458,
      "loss": 4.588,
      "step": 257
    },
    {
      "epoch": 10.32,
      "learning_rate": 0.001452,
      "loss": 2.9677,
      "step": 258
    },
    {
      "epoch": 10.36,
      "learning_rate": 0.001446,
      "loss": 7.2898,
      "step": 259
    },
    {
      "epoch": 10.4,
      "learning_rate": 0.0014399999999999999,
      "loss": 3.4824,
      "step": 260
    },
    {
      "epoch": 10.44,
      "learning_rate": 0.001434,
      "loss": 4.6751,
      "step": 261
    },
    {
      "epoch": 10.48,
      "learning_rate": 0.001428,
      "loss": 3.9662,
      "step": 262
    },
    {
      "epoch": 10.52,
      "learning_rate": 0.0014219999999999999,
      "loss": 4.0289,
      "step": 263
    },
    {
      "epoch": 10.56,
      "learning_rate": 0.001416,
      "loss": 4.3522,
      "step": 264
    },
    {
      "epoch": 10.6,
      "learning_rate": 0.00141,
      "loss": 5.318,
      "step": 265
    },
    {
      "epoch": 10.64,
      "learning_rate": 0.001404,
      "loss": 4.6105,
      "step": 266
    },
    {
      "epoch": 10.68,
      "learning_rate": 0.0013980000000000002,
      "loss": 4.579,
      "step": 267
    },
    {
      "epoch": 10.72,
      "learning_rate": 0.001392,
      "loss": 3.9005,
      "step": 268
    },
    {
      "epoch": 10.76,
      "learning_rate": 0.001386,
      "loss": 3.9875,
      "step": 269
    },
    {
      "epoch": 10.8,
      "learning_rate": 0.0013800000000000002,
      "loss": 2.0298,
      "step": 270
    },
    {
      "epoch": 10.84,
      "learning_rate": 0.001374,
      "loss": 4.4628,
      "step": 271
    },
    {
      "epoch": 10.88,
      "learning_rate": 0.001368,
      "loss": 4.9585,
      "step": 272
    },
    {
      "epoch": 10.92,
      "learning_rate": 0.0013620000000000001,
      "loss": 2.6846,
      "step": 273
    },
    {
      "epoch": 10.96,
      "learning_rate": 0.001356,
      "loss": 4.2721,
      "step": 274
    },
    {
      "epoch": 11.0,
      "learning_rate": 0.00135,
      "loss": 3.2891,
      "step": 275
    },
    {
      "epoch": 11.04,
      "learning_rate": 0.0013440000000000001,
      "loss": 3.4646,
      "step": 276
    },
    {
      "epoch": 11.08,
      "learning_rate": 0.001338,
      "loss": 5.2972,
      "step": 277
    },
    {
      "epoch": 11.12,
      "learning_rate": 0.001332,
      "loss": 3.2873,
      "step": 278
    },
    {
      "epoch": 11.16,
      "learning_rate": 0.0013260000000000001,
      "loss": 5.5985,
      "step": 279
    },
    {
      "epoch": 11.2,
      "learning_rate": 0.00132,
      "loss": 3.9956,
      "step": 280
    },
    {
      "epoch": 11.24,
      "learning_rate": 0.001314,
      "loss": 2.6753,
      "step": 281
    },
    {
      "epoch": 11.28,
      "learning_rate": 0.001308,
      "loss": 3.9787,
      "step": 282
    },
    {
      "epoch": 11.32,
      "learning_rate": 0.001302,
      "loss": 4.915,
      "step": 283
    },
    {
      "epoch": 11.36,
      "learning_rate": 0.001296,
      "loss": 2.8605,
      "step": 284
    },
    {
      "epoch": 11.4,
      "learning_rate": 0.00129,
      "loss": 4.7971,
      "step": 285
    },
    {
      "epoch": 11.44,
      "learning_rate": 0.001284,
      "loss": 4.6343,
      "step": 286
    },
    {
      "epoch": 11.48,
      "learning_rate": 0.001278,
      "loss": 7.2097,
      "step": 287
    },
    {
      "epoch": 11.52,
      "learning_rate": 0.001272,
      "loss": 4.4517,
      "step": 288
    },
    {
      "epoch": 11.56,
      "learning_rate": 0.001266,
      "loss": 5.6526,
      "step": 289
    },
    {
      "epoch": 11.6,
      "learning_rate": 0.00126,
      "loss": 2.0249,
      "step": 290
    },
    {
      "epoch": 11.64,
      "learning_rate": 0.001254,
      "loss": 3.769,
      "step": 291
    },
    {
      "epoch": 11.68,
      "learning_rate": 0.001248,
      "loss": 4.5495,
      "step": 292
    },
    {
      "epoch": 11.72,
      "learning_rate": 0.001242,
      "loss": 4.6432,
      "step": 293
    },
    {
      "epoch": 11.76,
      "learning_rate": 0.001236,
      "loss": 4.5049,
      "step": 294
    },
    {
      "epoch": 11.8,
      "learning_rate": 0.00123,
      "loss": 3.7659,
      "step": 295
    },
    {
      "epoch": 11.84,
      "learning_rate": 0.001224,
      "loss": 4.309,
      "step": 296
    },
    {
      "epoch": 11.88,
      "learning_rate": 0.0012180000000000001,
      "loss": 3.9397,
      "step": 297
    },
    {
      "epoch": 11.92,
      "learning_rate": 0.0012120000000000002,
      "loss": 4.5547,
      "step": 298
    },
    {
      "epoch": 11.96,
      "learning_rate": 0.001206,
      "loss": 4.2441,
      "step": 299
    },
    {
      "epoch": 12.0,
      "learning_rate": 0.0012000000000000001,
      "loss": 4.9266,
      "step": 300
    },
    {
      "epoch": 12.04,
      "learning_rate": 0.0011940000000000002,
      "loss": 4.5332,
      "step": 301
    },
    {
      "epoch": 12.08,
      "learning_rate": 0.001188,
      "loss": 4.4664,
      "step": 302
    },
    {
      "epoch": 12.12,
      "learning_rate": 0.001182,
      "loss": 4.3003,
      "step": 303
    },
    {
      "epoch": 12.16,
      "learning_rate": 0.001176,
      "loss": 3.9635,
      "step": 304
    },
    {
      "epoch": 12.2,
      "learning_rate": 0.00117,
      "loss": 3.4316,
      "step": 305
    },
    {
      "epoch": 12.24,
      "learning_rate": 0.001164,
      "loss": 2.6554,
      "step": 306
    },
    {
      "epoch": 12.28,
      "learning_rate": 0.001158,
      "loss": 4.5523,
      "step": 307
    },
    {
      "epoch": 12.32,
      "learning_rate": 0.001152,
      "loss": 7.1443,
      "step": 308
    },
    {
      "epoch": 12.36,
      "learning_rate": 0.001146,
      "loss": 3.9296,
      "step": 309
    },
    {
      "epoch": 12.4,
      "learning_rate": 0.00114,
      "loss": 3.999,
      "step": 310
    },
    {
      "epoch": 12.44,
      "learning_rate": 0.001134,
      "loss": 4.6223,
      "step": 311
    },
    {
      "epoch": 12.48,
      "learning_rate": 0.001128,
      "loss": 5.6164,
      "step": 312
    },
    {
      "epoch": 12.52,
      "learning_rate": 0.001122,
      "loss": 3.7487,
      "step": 313
    },
    {
      "epoch": 12.56,
      "learning_rate": 0.001116,
      "loss": 2.7995,
      "step": 314
    },
    {
      "epoch": 12.6,
      "learning_rate": 0.00111,
      "loss": 4.6794,
      "step": 315
    },
    {
      "epoch": 12.64,
      "learning_rate": 0.001104,
      "loss": 2.0163,
      "step": 316
    },
    {
      "epoch": 12.68,
      "learning_rate": 0.001098,
      "loss": 3.693,
      "step": 317
    },
    {
      "epoch": 12.72,
      "learning_rate": 0.001092,
      "loss": 5.2342,
      "step": 318
    },
    {
      "epoch": 12.76,
      "learning_rate": 0.001086,
      "loss": 4.8891,
      "step": 319
    },
    {
      "epoch": 12.8,
      "learning_rate": 0.00108,
      "loss": 4.9003,
      "step": 320
    },
    {
      "epoch": 12.84,
      "learning_rate": 0.001074,
      "loss": 5.5414,
      "step": 321
    },
    {
      "epoch": 12.88,
      "learning_rate": 0.001068,
      "loss": 4.54,
      "step": 322
    },
    {
      "epoch": 12.92,
      "learning_rate": 0.001062,
      "loss": 3.2634,
      "step": 323
    },
    {
      "epoch": 12.96,
      "learning_rate": 0.0010559999999999999,
      "loss": 4.4228,
      "step": 324
    },
    {
      "epoch": 13.0,
      "learning_rate": 0.00105,
      "loss": 4.2278,
      "step": 325
    },
    {
      "epoch": 13.04,
      "learning_rate": 0.001044,
      "loss": 4.538,
      "step": 326
    },
    {
      "epoch": 13.08,
      "learning_rate": 0.0010379999999999999,
      "loss": 4.4061,
      "step": 327
    },
    {
      "epoch": 13.12,
      "learning_rate": 0.001032,
      "loss": 3.4085,
      "step": 328
    },
    {
      "epoch": 13.16,
      "learning_rate": 0.001026,
      "loss": 3.2608,
      "step": 329
    },
    {
      "epoch": 13.2,
      "learning_rate": 0.00102,
      "loss": 3.9573,
      "step": 330
    },
    {
      "epoch": 13.24,
      "learning_rate": 0.0010140000000000001,
      "loss": 4.2224,
      "step": 331
    },
    {
      "epoch": 13.28,
      "learning_rate": 0.001008,
      "loss": 4.621,
      "step": 332
    },
    {
      "epoch": 13.32,
      "learning_rate": 0.001002,
      "loss": 4.4648,
      "step": 333
    },
    {
      "epoch": 13.36,
      "learning_rate": 0.0009960000000000001,
      "loss": 4.8784,
      "step": 334
    },
    {
      "epoch": 13.4,
      "learning_rate": 0.00099,
      "loss": 2.6327,
      "step": 335
    },
    {
      "epoch": 13.44,
      "learning_rate": 0.000984,
      "loss": 3.9412,
      "step": 336
    },
    {
      "epoch": 13.48,
      "learning_rate": 0.0009780000000000001,
      "loss": 5.558,
      "step": 337
    },
    {
      "epoch": 13.52,
      "learning_rate": 0.0009720000000000001,
      "loss": 2.0127,
      "step": 338
    },
    {
      "epoch": 13.56,
      "learning_rate": 0.0009660000000000001,
      "loss": 4.2762,
      "step": 339
    },
    {
      "epoch": 13.6,
      "learning_rate": 0.00096,
      "loss": 7.1024,
      "step": 340
    },
    {
      "epoch": 13.64,
      "learning_rate": 0.000954,
      "loss": 4.8881,
      "step": 341
    },
    {
      "epoch": 13.68,
      "learning_rate": 0.0009480000000000001,
      "loss": 3.7451,
      "step": 342
    },
    {
      "epoch": 13.72,
      "learning_rate": 0.000942,
      "loss": 3.5624,
      "step": 343
    },
    {
      "epoch": 13.76,
      "learning_rate": 0.000936,
      "loss": 3.9054,
      "step": 344
    },
    {
      "epoch": 13.8,
      "learning_rate": 0.00093,
      "loss": 5.4938,
      "step": 345
    },
    {
      "epoch": 13.84,
      "learning_rate": 0.000924,
      "loss": 4.4927,
      "step": 346
    },
    {
      "epoch": 13.88,
      "learning_rate": 0.000918,
      "loss": 2.7047,
      "step": 347
    },
    {
      "epoch": 13.92,
      "learning_rate": 0.000912,
      "loss": 5.2143,
      "step": 348
    },
    {
      "epoch": 13.96,
      "learning_rate": 0.000906,
      "loss": 4.4036,
      "step": 349
    },
    {
      "epoch": 14.0,
      "learning_rate": 0.0009,
      "loss": 4.5863,
      "step": 350
    },
    {
      "epoch": 14.04,
      "learning_rate": 0.0008939999999999999,
      "loss": 2.0107,
      "step": 351
    },
    {
      "epoch": 14.08,
      "learning_rate": 0.000888,
      "loss": 4.3483,
      "step": 352
    },
    {
      "epoch": 14.12,
      "learning_rate": 0.000882,
      "loss": 3.9482,
      "step": 353
    },
    {
      "epoch": 14.16,
      "learning_rate": 0.0008759999999999999,
      "loss": 5.4721,
      "step": 354
    },
    {
      "epoch": 14.2,
      "learning_rate": 0.00087,
      "loss": 2.6769,
      "step": 355
    },
    {
      "epoch": 14.24,
      "learning_rate": 0.000864,
      "loss": 4.5456,
      "step": 356
    },
    {
      "epoch": 14.28,
      "learning_rate": 0.0008579999999999999,
      "loss": 4.1989,
      "step": 357
    },
    {
      "epoch": 14.32,
      "learning_rate": 0.0008519999999999999,
      "loss": 3.2545,
      "step": 358
    },
    {
      "epoch": 14.36,
      "learning_rate": 0.000846,
      "loss": 4.5221,
      "step": 359
    },
    {
      "epoch": 14.4,
      "learning_rate": 0.0008400000000000001,
      "loss": 5.523,
      "step": 360
    },
    {
      "epoch": 14.44,
      "learning_rate": 0.0008340000000000001,
      "loss": 3.463,
      "step": 361
    },
    {
      "epoch": 14.48,
      "learning_rate": 0.0008280000000000001,
      "loss": 3.3883,
      "step": 362
    },
    {
      "epoch": 14.52,
      "learning_rate": 0.000822,
      "loss": 4.6019,
      "step": 363
    },
    {
      "epoch": 14.56,
      "learning_rate": 0.0008160000000000001,
      "loss": 7.0916,
      "step": 364
    },
    {
      "epoch": 14.6,
      "learning_rate": 0.0008100000000000001,
      "loss": 4.8595,
      "step": 365
    },
    {
      "epoch": 14.64,
      "learning_rate": 0.000804,
      "loss": 4.3856,
      "step": 366
    },
    {
      "epoch": 14.68,
      "learning_rate": 0.0007980000000000001,
      "loss": 3.8831,
      "step": 367
    },
    {
      "epoch": 14.72,
      "learning_rate": 0.0007920000000000001,
      "loss": 3.9129,
      "step": 368
    },
    {
      "epoch": 14.76,
      "learning_rate": 0.000786,
      "loss": 2.6161,
      "step": 369
    },
    {
      "epoch": 14.8,
      "learning_rate": 0.0007800000000000001,
      "loss": 3.7433,
      "step": 370
    },
    {
      "epoch": 14.84,
      "learning_rate": 0.0007740000000000001,
      "loss": 4.2671,
      "step": 371
    },
    {
      "epoch": 14.88,
      "learning_rate": 0.000768,
      "loss": 5.191,
      "step": 372
    },
    {
      "epoch": 14.92,
      "learning_rate": 0.000762,
      "loss": 4.3977,
      "step": 373
    },
    {
      "epoch": 14.96,
      "learning_rate": 0.000756,
      "loss": 4.8681,
      "step": 374
    },
    {
      "epoch": 15.0,
      "learning_rate": 0.00075,
      "loss": 4.4745,
      "step": 375
    },
    {
      "epoch": 15.04,
      "learning_rate": 0.000744,
      "loss": 3.8811,
      "step": 376
    },
    {
      "epoch": 15.08,
      "learning_rate": 0.000738,
      "loss": 2.627,
      "step": 377
    },
    {
      "epoch": 15.12,
      "learning_rate": 0.000732,
      "loss": 4.4723,
      "step": 378
    },
    {
      "epoch": 15.16,
      "learning_rate": 0.000726,
      "loss": 3.8905,
      "step": 379
    },
    {
      "epoch": 15.2,
      "learning_rate": 0.0007199999999999999,
      "loss": 3.3808,
      "step": 380
    },
    {
      "epoch": 15.24,
      "learning_rate": 0.000714,
      "loss": 2.0065,
      "step": 381
    },
    {
      "epoch": 15.28,
      "learning_rate": 0.000708,
      "loss": 5.494,
      "step": 382
    },
    {
      "epoch": 15.32,
      "learning_rate": 0.000702,
      "loss": 4.3332,
      "step": 383
    },
    {
      "epoch": 15.36,
      "learning_rate": 0.000696,
      "loss": 2.6038,
      "step": 384
    },
    {
      "epoch": 15.4,
      "learning_rate": 0.0006900000000000001,
      "loss": 3.2444,
      "step": 385
    },
    {
      "epoch": 15.44,
      "learning_rate": 0.000684,
      "loss": 3.7445,
      "step": 386
    },
    {
      "epoch": 15.48,
      "learning_rate": 0.000678,
      "loss": 4.5113,
      "step": 387
    },
    {
      "epoch": 15.52,
      "learning_rate": 0.0006720000000000001,
      "loss": 5.1779,
      "step": 388
    },
    {
      "epoch": 15.56,
      "learning_rate": 0.000666,
      "loss": 4.8595,
      "step": 389
    },
    {
      "epoch": 15.6,
      "learning_rate": 0.00066,
      "loss": 5.4307,
      "step": 390
    },
    {
      "epoch": 15.64,
      "learning_rate": 0.000654,
      "loss": 7.0551,
      "step": 391
    },
    {
      "epoch": 15.68,
      "learning_rate": 0.000648,
      "loss": 4.2539,
      "step": 392
    },
    {
      "epoch": 15.72,
      "learning_rate": 0.000642,
      "loss": 4.4854,
      "step": 393
    },
    {
      "epoch": 15.76,
      "learning_rate": 0.000636,
      "loss": 4.5919,
      "step": 394
    },
    {
      "epoch": 15.8,
      "learning_rate": 0.00063,
      "loss": 3.9424,
      "step": 395
    },
    {
      "epoch": 15.84,
      "learning_rate": 0.000624,
      "loss": 4.8439,
      "step": 396
    },
    {
      "epoch": 15.88,
      "learning_rate": 0.000618,
      "loss": 4.3855,
      "step": 397
    },
    {
      "epoch": 15.92,
      "learning_rate": 0.000612,
      "loss": 3.3679,
      "step": 398
    },
    {
      "epoch": 15.96,
      "learning_rate": 0.0006060000000000001,
      "loss": 4.2698,
      "step": 399
    },
    {
      "epoch": 16.0,
      "learning_rate": 0.0006000000000000001,
      "loss": 4.1726,
      "step": 400
    },
    {
      "epoch": 16.04,
      "learning_rate": 0.000594,
      "loss": 5.1772,
      "step": 401
    },
    {
      "epoch": 16.08,
      "learning_rate": 0.000588,
      "loss": 5.4925,
      "step": 402
    },
    {
      "epoch": 16.12,
      "learning_rate": 0.000582,
      "loss": 4.3802,
      "step": 403
    },
    {
      "epoch": 16.16,
      "learning_rate": 0.000576,
      "loss": 3.2453,
      "step": 404
    },
    {
      "epoch": 16.2,
      "learning_rate": 0.00057,
      "loss": 3.9348,
      "step": 405
    },
    {
      "epoch": 16.24,
      "learning_rate": 0.000564,
      "loss": 3.3322,
      "step": 406
    },
    {
      "epoch": 16.28,
      "learning_rate": 0.000558,
      "loss": 2.5938,
      "step": 407
    },
    {
      "epoch": 16.32,
      "learning_rate": 0.000552,
      "loss": 4.8523,
      "step": 408
    },
    {
      "epoch": 16.36,
      "learning_rate": 0.000546,
      "loss": 4.8395,
      "step": 409
    },
    {
      "epoch": 16.4,
      "learning_rate": 0.00054,
      "loss": 4.4505,
      "step": 410
    },
    {
      "epoch": 16.44,
      "learning_rate": 0.000534,
      "loss": 5.4163,
      "step": 411
    },
    {
      "epoch": 16.48,
      "learning_rate": 0.0005279999999999999,
      "loss": 4.1687,
      "step": 412
    },
    {
      "epoch": 16.52,
      "learning_rate": 0.000522,
      "loss": 4.4383,
      "step": 413
    },
    {
      "epoch": 16.56,
      "learning_rate": 0.000516,
      "loss": 4.2696,
      "step": 414
    },
    {
      "epoch": 16.6,
      "learning_rate": 0.00051,
      "loss": 2.5741,
      "step": 415
    },
    {
      "epoch": 16.64,
      "learning_rate": 0.000504,
      "loss": 4.2381,
      "step": 416
    },
    {
      "epoch": 16.68,
      "learning_rate": 0.0004980000000000001,
      "loss": 2.0014,
      "step": 417
    },
    {
      "epoch": 16.72,
      "learning_rate": 0.000492,
      "loss": 4.5862,
      "step": 418
    },
    {
      "epoch": 16.76,
      "learning_rate": 0.00048600000000000005,
      "loss": 4.5051,
      "step": 419
    },
    {
      "epoch": 16.8,
      "learning_rate": 0.00048,
      "loss": 7.0292,
      "step": 420
    },
    {
      "epoch": 16.84,
      "learning_rate": 0.00047400000000000003,
      "loss": 3.8746,
      "step": 421
    },
    {
      "epoch": 16.88,
      "learning_rate": 0.000468,
      "loss": 4.2428,
      "step": 422
    },
    {
      "epoch": 16.92,
      "learning_rate": 0.000462,
      "loss": 3.356,
      "step": 423
    },
    {
      "epoch": 16.96,
      "learning_rate": 0.000456,
      "loss": 3.8623,
      "step": 424
    },
    {
      "epoch": 17.0,
      "learning_rate": 0.00045,
      "loss": 3.7319,
      "step": 425
    },
    {
      "epoch": 17.04,
      "learning_rate": 0.000444,
      "loss": 7.0113,
      "step": 426
    },
    {
      "epoch": 17.08,
      "learning_rate": 0.00043799999999999997,
      "loss": 4.2443,
      "step": 427
    },
    {
      "epoch": 17.12,
      "learning_rate": 0.000432,
      "loss": 3.3525,
      "step": 428
    },
    {
      "epoch": 17.16,
      "learning_rate": 0.00042599999999999995,
      "loss": 3.9279,
      "step": 429
    },
    {
      "epoch": 17.2,
      "learning_rate": 0.00042000000000000007,
      "loss": 1.9996,
      "step": 430
    },
    {
      "epoch": 17.24,
      "learning_rate": 0.00041400000000000003,
      "loss": 3.8589,
      "step": 431
    },
    {
      "epoch": 17.28,
      "learning_rate": 0.00040800000000000005,
      "loss": 4.5011,
      "step": 432
    },
    {
      "epoch": 17.32,
      "learning_rate": 0.000402,
      "loss": 4.2295,
      "step": 433
    },
    {
      "epoch": 17.36,
      "learning_rate": 0.00039600000000000003,
      "loss": 4.3679,
      "step": 434
    },
    {
      "epoch": 17.4,
      "learning_rate": 0.00039000000000000005,
      "loss": 5.48,
      "step": 435
    },
    {
      "epoch": 17.44,
      "learning_rate": 0.000384,
      "loss": 4.8433,
      "step": 436
    },
    {
      "epoch": 17.48,
      "learning_rate": 0.000378,
      "loss": 3.8677,
      "step": 437
    },
    {
      "epoch": 17.52,
      "learning_rate": 0.000372,
      "loss": 3.3059,
      "step": 438
    },
    {
      "epoch": 17.56,
      "learning_rate": 0.000366,
      "loss": 4.5728,
      "step": 439
    },
    {
      "epoch": 17.6,
      "learning_rate": 0.00035999999999999997,
      "loss": 4.4394,
      "step": 440
    },
    {
      "epoch": 17.64,
      "learning_rate": 0.000354,
      "loss": 2.5812,
      "step": 441
    },
    {
      "epoch": 17.68,
      "learning_rate": 0.000348,
      "loss": 5.4036,
      "step": 442
    },
    {
      "epoch": 17.72,
      "learning_rate": 0.000342,
      "loss": 4.4238,
      "step": 443
    },
    {
      "epoch": 17.76,
      "learning_rate": 0.00033600000000000004,
      "loss": 2.5529,
      "step": 444
    },
    {
      "epoch": 17.8,
      "learning_rate": 0.00033,
      "loss": 4.2039,
      "step": 445
    },
    {
      "epoch": 17.84,
      "learning_rate": 0.000324,
      "loss": 3.7291,
      "step": 446
    },
    {
      "epoch": 17.88,
      "learning_rate": 0.000318,
      "loss": 3.2371,
      "step": 447
    },
    {
      "epoch": 17.92,
      "learning_rate": 0.000312,
      "loss": 4.8279,
      "step": 448
    },
    {
      "epoch": 17.96,
      "learning_rate": 0.000306,
      "loss": 4.1576,
      "step": 449
    },
    {
      "epoch": 18.0,
      "learning_rate": 0.00030000000000000003,
      "loss": 5.1545,
      "step": 450
    },
    {
      "epoch": 18.04,
      "learning_rate": 0.000294,
      "loss": 4.4986,
      "step": 451
    },
    {
      "epoch": 18.08,
      "learning_rate": 0.000288,
      "loss": 3.7296,
      "step": 452
    },
    {
      "epoch": 18.12,
      "learning_rate": 0.000282,
      "loss": 4.4018,
      "step": 453
    },
    {
      "epoch": 18.16,
      "learning_rate": 0.000276,
      "loss": 4.214,
      "step": 454
    },
    {
      "epoch": 18.2,
      "learning_rate": 0.00027,
      "loss": 5.3942,
      "step": 455
    },
    {
      "epoch": 18.24,
      "learning_rate": 0.00026399999999999997,
      "loss": 4.5761,
      "step": 456
    },
    {
      "epoch": 18.28,
      "learning_rate": 0.000258,
      "loss": 3.2552,
      "step": 457
    },
    {
      "epoch": 18.32,
      "learning_rate": 0.000252,
      "loss": 4.3662,
      "step": 458
    },
    {
      "epoch": 18.36,
      "learning_rate": 0.000246,
      "loss": 4.4378,
      "step": 459
    },
    {
      "epoch": 18.4,
      "learning_rate": 0.00024,
      "loss": 5.1516,
      "step": 460
    },
    {
      "epoch": 18.44,
      "learning_rate": 0.000234,
      "loss": 3.8519,
      "step": 461
    },
    {
      "epoch": 18.48,
      "learning_rate": 0.000228,
      "loss": 4.1563,
      "step": 462
    },
    {
      "epoch": 18.52,
      "learning_rate": 0.000222,
      "loss": 3.8461,
      "step": 463
    },
    {
      "epoch": 18.56,
      "learning_rate": 0.000216,
      "loss": 3.9262,
      "step": 464
    },
    {
      "epoch": 18.6,
      "learning_rate": 0.00021000000000000004,
      "loss": 4.8361,
      "step": 465
    },
    {
      "epoch": 18.64,
      "learning_rate": 0.00020400000000000003,
      "loss": 3.2344,
      "step": 466
    },
    {
      "epoch": 18.68,
      "learning_rate": 0.00019800000000000002,
      "loss": 4.8244,
      "step": 467
    },
    {
      "epoch": 18.72,
      "learning_rate": 0.000192,
      "loss": 6.9973,
      "step": 468
    },
    {
      "epoch": 18.76,
      "learning_rate": 0.000186,
      "loss": 5.441,
      "step": 469
    },
    {
      "epoch": 18.8,
      "learning_rate": 0.00017999999999999998,
      "loss": 3.3438,
      "step": 470
    },
    {
      "epoch": 18.84,
      "learning_rate": 0.000174,
      "loss": 2.5796,
      "step": 471
    },
    {
      "epoch": 18.88,
      "learning_rate": 0.00016800000000000002,
      "loss": 4.2317,
      "step": 472
    },
    {
      "epoch": 18.92,
      "learning_rate": 0.000162,
      "loss": 2.5306,
      "step": 473
    },
    {
      "epoch": 18.96,
      "learning_rate": 0.000156,
      "loss": 1.9985,
      "step": 474
    },
    {
      "epoch": 19.0,
      "learning_rate": 0.00015000000000000001,
      "loss": 4.1859,
      "step": 475
    },
    {
      "epoch": 19.04,
      "learning_rate": 0.000144,
      "loss": 6.993,
      "step": 476
    },
    {
      "epoch": 19.08,
      "learning_rate": 0.000138,
      "loss": 4.5737,
      "step": 477
    },
    {
      "epoch": 19.12,
      "learning_rate": 0.00013199999999999998,
      "loss": 4.153,
      "step": 478
    },
    {
      "epoch": 19.16,
      "learning_rate": 0.000126,
      "loss": 4.8347,
      "step": 479
    },
    {
      "epoch": 19.2,
      "learning_rate": 0.00012,
      "loss": 4.4341,
      "step": 480
    },
    {
      "epoch": 19.24,
      "learning_rate": 0.000114,
      "loss": 4.3636,
      "step": 481
    },
    {
      "epoch": 19.28,
      "learning_rate": 0.000108,
      "loss": 4.8233,
      "step": 482
    },
    {
      "epoch": 19.32,
      "learning_rate": 0.00010200000000000001,
      "loss": 5.1494,
      "step": 483
    },
    {
      "epoch": 19.36,
      "learning_rate": 9.6e-05,
      "loss": 3.8406,
      "step": 484
    },
    {
      "epoch": 19.4,
      "learning_rate": 8.999999999999999e-05,
      "loss": 3.3413,
      "step": 485
    },
    {
      "epoch": 19.44,
      "learning_rate": 8.400000000000001e-05,
      "loss": 4.378,
      "step": 486
    },
    {
      "epoch": 19.48,
      "learning_rate": 7.8e-05,
      "loss": 3.7255,
      "step": 487
    },
    {
      "epoch": 19.52,
      "learning_rate": 7.2e-05,
      "loss": 3.2376,
      "step": 488
    },
    {
      "epoch": 19.56,
      "learning_rate": 6.599999999999999e-05,
      "loss": 1.9977,
      "step": 489
    },
    {
      "epoch": 19.6,
      "learning_rate": 6e-05,
      "loss": 3.2343,
      "step": 490
    },
    {
      "epoch": 19.64,
      "learning_rate": 5.4e-05,
      "loss": 4.2272,
      "step": 491
    },
    {
      "epoch": 19.68,
      "learning_rate": 4.8e-05,
      "loss": 5.3854,
      "step": 492
    },
    {
      "epoch": 19.72,
      "learning_rate": 4.2000000000000004e-05,
      "loss": 3.8518,
      "step": 493
    },
    {
      "epoch": 19.76,
      "learning_rate": 3.6e-05,
      "loss": 4.1777,
      "step": 494
    },
    {
      "epoch": 19.8,
      "learning_rate": 3e-05,
      "loss": 2.5774,
      "step": 495
    },
    {
      "epoch": 19.84,
      "learning_rate": 2.4e-05,
      "loss": 5.4431,
      "step": 496
    },
    {
      "epoch": 19.88,
      "learning_rate": 1.8e-05,
      "loss": 4.199,
      "step": 497
    },
    {
      "epoch": 19.92,
      "learning_rate": 1.2e-05,
      "loss": 3.9236,
      "step": 498
    },
    {
      "epoch": 19.96,
      "learning_rate": 6e-06,
      "loss": 2.5292,
      "step": 499
    },
    {
      "epoch": 20.0,
      "learning_rate": 0.0,
      "loss": 4.496,
      "step": 500
    }
  ],
  "logging_steps": 1,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "total_flos": 16216094638080.0,
  "trial_name": null,
  "trial_params": null
}
